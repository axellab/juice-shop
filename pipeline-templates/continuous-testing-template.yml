# Continuous Testing Pipeline Template
# Based on OWASP Juice Shop comprehensive testing practices
# Adapt this template for your project by replacing variables and customizing test suites

name: "Continuous Testing Pipeline"

on:
  push:
    branches:
      - main
      - develop
      - feature/*
      - hotfix/*
  pull_request:
    branches:
      - main
      - develop
  schedule:
    # Run comprehensive tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - integration
          - e2e
          - performance
          - security
          - accessibility

env:
  # Customize these variables for your project
  NODE_DEFAULT_VERSION: 20
  PROJECT_NAME: "your-project-name"
  TEST_ENVIRONMENT_URL: "http://localhost:3000"
  
  # Test configuration
  CYPRESS_CACHE_FOLDER: ~/.cache/Cypress
  JEST_TIMEOUT: 30000
  E2E_TIMEOUT: 120000

jobs:
  # Setup and Configuration
  setup:
    runs-on: ubuntu-latest
    outputs:
      test_matrix: ${{ steps.matrix.outputs.test_matrix }}
      should_run_tests: ${{ steps.matrix.outputs.should_run_tests }}
    steps:
      - name: "Checkout Repository"
        uses: actions/checkout@v4
        
      - name: "Setup Test Matrix"
        id: matrix
        run: |
          # Determine which tests to run based on trigger and inputs
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            if [ "${{ github.event.inputs.test_suite }}" == "all" ]; then
              echo "test_matrix=['unit', 'integration', 'e2e', 'performance', 'security', 'accessibility']" >> $GITHUB_OUTPUT
            else
              echo "test_matrix=['${{ github.event.inputs.test_suite }}']" >> $GITHUB_OUTPUT
            fi
          elif [ "${{ github.event_name }}" == "schedule" ]; then
            echo "test_matrix=['unit', 'integration', 'e2e', 'performance', 'security', 'accessibility']" >> $GITHUB_OUTPUT
          else
            echo "test_matrix=['unit', 'integration', 'e2e']" >> $GITHUB_OUTPUT
          fi
          echo "should_run_tests=true" >> $GITHUB_OUTPUT

  # Unit Testing
  unit-tests:
    runs-on: ${{ matrix.os }}
    needs: setup
    if: needs.setup.outputs.should_run_tests == 'true' && contains(needs.setup.outputs.test_matrix, 'unit')
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        node-version: [18, 20, 22]
      fail-fast: false
    name: "Unit Tests - ${{ matrix.os }} - Node ${{ matrix.node-version }}"
    steps:
      - name: "Checkout Repository"
        uses: actions/checkout@v4
        
      - name: "Setup Node.js ${{ matrix.node-version }}"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
          
      - name: "Install Dependencies"
        run: npm ci
        
      - name: "Run Unit Tests"
        run: |
          npm run test:unit -- --coverage --ci --watchAll=false
        env:
          CI: true
          
      - name: "Run Frontend Unit Tests"
        run: |
          cd frontend
          npm run test -- --watch=false --browsers=ChromeHeadless --code-coverage
          
      - name: "Upload Coverage Reports"
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-coverage-${{ matrix.os }}-${{ matrix.node-version }}
          path: |
            coverage/
            frontend/coverage/
            
      - name: "Publish Test Results"
        uses: dorny/test-reporter@v1
        if: always()
        with:
          name: Unit Tests - ${{ matrix.os }} - Node ${{ matrix.node-version }}
          path: test-results/unit/junit.xml
          reporter: jest-junit

  # Integration Testing
  integration-tests:
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_tests == 'true' && contains(needs.setup.outputs.test_matrix, 'integration')
    name: "Integration Tests"
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:6
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
          
    steps:
      - name: "Checkout Repository"
        uses: actions/checkout@v4
        
      - name: "Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_DEFAULT_VERSION }}
          cache: 'npm'
          
      - name: "Install Dependencies"
        run: npm ci
        
      - name: "Setup Test Database"
        run: |
          npm run db:migrate
          npm run db:seed:test
        env:
          DATABASE_URL: postgres://postgres:postgres@localhost:5432/test_db
          
      - name: "Run Integration Tests"
        run: |
          npm run test:integration
        env:
          NODE_ENV: test
          DATABASE_URL: postgres://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379
          
      - name: "Upload Integration Test Results"
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: test-results/integration/

  # API Testing
  api-tests:
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_tests == 'true' && contains(needs.setup.outputs.test_matrix, 'integration')
    name: "API Tests"
    steps:
      - name: "Checkout Repository"
        uses: actions/checkout@v4
        
      - name: "Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_DEFAULT_VERSION }}
          cache: 'npm'
          
      - name: "Install Dependencies"
        run: npm ci
        
      - name: "Start Application"
        run: |
          npm run start &
          sleep 15
          
      - name: "Wait for Application"
        run: |
          timeout 60 bash -c 'until curl -f http://localhost:3000/health; do sleep 2; done'
          
      - name: "Run API Tests with Frisby"
        run: |
          npm run test:api
        env:
          NODE_ENV: test
          API_BASE_URL: http://localhost:3000
          
      - name: "Run Postman Collection Tests"
        run: |
          npm install -g newman
          newman run test/postman/collection.json -e test/postman/environment.json
          
      - name: "Upload API Test Coverage"
        uses: actions/upload-artifact@v4
        with:
          name: api-test-coverage
          path: coverage/api/

  # End-to-End Testing
  e2e-tests:
    runs-on: ${{ matrix.os }}
    needs: setup
    if: needs.setup.outputs.should_run_tests == 'true' && contains(needs.setup.outputs.test_matrix, 'e2e')
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]
        browser: [chrome, firefox, edge]
      fail-fast: false
    name: "E2E Tests - ${{ matrix.browser }} on ${{ matrix.os }}"
    steps:
      - name: "Checkout Repository"
        uses: actions/checkout@v4
        
      - name: "Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_DEFAULT_VERSION }}
          cache: 'npm'
          
      - name: "Install Dependencies"
        run: npm ci
        
      - name: "Build Application"
        run: npm run build
        
      - name: "Run Cypress E2E Tests"
        uses: cypress-io/github-action@v6
        with:
          browser: ${{ matrix.browser }}
          start: npm run start
          wait-on: ${{ env.TEST_ENVIRONMENT_URL }}
          wait-on-timeout: 120
          record: true
          parallel: true
          group: ${{ matrix.browser }}-${{ matrix.os }}
        env:
          CYPRESS_RECORD_KEY: ${{ secrets.CYPRESS_RECORD_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: "Upload E2E Test Videos"
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: e2e-videos-${{ matrix.browser }}-${{ matrix.os }}
          path: cypress/videos/
          
      - name: "Upload E2E Test Screenshots"
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: e2e-screenshots-${{ matrix.browser }}-${{ matrix.os }}
          path: cypress/screenshots/

  # Performance Testing
  performance-tests:
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_tests == 'true' && contains(needs.setup.outputs.test_matrix, 'performance')
    name: "Performance Tests"
    steps:
      - name: "Checkout Repository"
        uses: actions/checkout@v4
        
      - name: "Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_DEFAULT_VERSION }}
          cache: 'npm'
          
      - name: "Install Dependencies"
        run: npm ci
        
      - name: "Build Application"
        run: npm run build
        
      - name: "Start Application"
        run: |
          npm run start &
          sleep 15
          
      - name: "Run Lighthouse Performance Tests"
        uses: treosh/lighthouse-ci-action@v10
        with:
          urls: |
            ${{ env.TEST_ENVIRONMENT_URL }}
            ${{ env.TEST_ENVIRONMENT_URL }}/login
            ${{ env.TEST_ENVIRONMENT_URL }}/search
          uploadArtifacts: true
          temporaryPublicStorage: true
          
      - name: "Run Artillery Load Tests"
        run: |
          npm install -g artillery
          artillery run test/performance/load-test.yml
          
      - name: "Run K6 Performance Tests"
        uses: grafana/k6-action@v0.3.0
        with:
          filename: test/performance/k6-test.js
          flags: --out json=results.json
          
      - name: "Upload Performance Results"
        uses: actions/upload-artifact@v4
        with:
          name: performance-test-results
          path: |
            results.json
            lighthouse-results/

  # Security Testing
  security-tests:
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_tests == 'true' && contains(needs.setup.outputs.test_matrix, 'security')
    name: "Security Tests"
    steps:
      - name: "Checkout Repository"
        uses: actions/checkout@v4
        
      - name: "Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_DEFAULT_VERSION }}
          cache: 'npm'
          
      - name: "Install Dependencies"
        run: npm ci
        
      - name: "Start Application"
        run: |
          npm run start &
          sleep 15
          
      - name: "Run OWASP ZAP Security Scan"
        uses: zaproxy/action-full-scan@v0.8.0
        with:
          target: ${{ env.TEST_ENVIRONMENT_URL }}
          rules_file_name: '.zap/rules.tsv'
          cmd_options: '-a -j'
          
      - name: "Run Snyk Security Scan"
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high
          
      - name: "Run npm audit"
        run: |
          npm audit --audit-level=moderate
          
      - name: "Upload Security Test Results"
        uses: actions/upload-artifact@v4
        with:
          name: security-test-results
          path: |
            security-results/
            .snyk

  # Accessibility Testing
  accessibility-tests:
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_tests == 'true' && contains(needs.setup.outputs.test_matrix, 'accessibility')
    name: "Accessibility Tests"
    steps:
      - name: "Checkout Repository"
        uses: actions/checkout@v4
        
      - name: "Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_DEFAULT_VERSION }}
          cache: 'npm'
          
      - name: "Install Dependencies"
        run: npm ci
        
      - name: "Start Application"
        run: |
          npm run start &
          sleep 15
          
      - name: "Run axe Accessibility Tests"
        run: |
          npm install -g @axe-core/cli
          axe ${{ env.TEST_ENVIRONMENT_URL }} --exit
          
      - name: "Run Pa11y Accessibility Tests"
        run: |
          npm install -g pa11y
          pa11y ${{ env.TEST_ENVIRONMENT_URL }}
          
      - name: "Upload Accessibility Test Results"
        uses: actions/upload-artifact@v4
        with:
          name: accessibility-test-results
          path: accessibility-results/

  # Test Coverage Consolidation
  coverage-report:
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, api-tests]
    if: always()
    name: "Coverage Report"
    steps:
      - name: "Checkout Repository"
        uses: actions/checkout@v4
        
      - name: "Download All Coverage Reports"
        uses: actions/download-artifact@v4
        with:
          pattern: '*-coverage*'
          path: coverage-reports/
          
      - name: "Merge Coverage Reports"
        run: |
          npm install -g nyc
          nyc merge coverage-reports/ coverage/merged-coverage.json
          nyc report --reporter=lcov --reporter=text --temp-dir=coverage/
          
      - name: "Upload to Codecov"
        uses: codecov/codecov-action@v4
        with:
          file: coverage/lcov.info
          flags: comprehensive
          name: comprehensive-coverage
          fail_ci_if_error: true
          
      - name: "Upload to Code Climate"
        uses: paambaati/codeclimate-action@v5.0.0
        env:
          CC_TEST_REPORTER_ID: ${{ secrets.CC_TEST_REPORTER_ID }}
        with:
          coverageLocations: coverage/lcov.info:lcov

  # Test Results Summary
  test-summary:
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, api-tests, e2e-tests, performance-tests, security-tests, accessibility-tests]
    if: always()
    name: "Test Results Summary"
    steps:
      - name: "Download All Test Results"
        uses: actions/download-artifact@v4
        with:
          pattern: '*-test-results*'
          path: test-results/
          
      - name: "Generate Test Summary Report"
        run: |
          echo "# Test Results Summary" > test-summary.md
          echo "## Test Execution Results" >> test-summary.md
          echo "- Unit Tests: ${{ needs.unit-tests.result }}" >> test-summary.md
          echo "- Integration Tests: ${{ needs.integration-tests.result }}" >> test-summary.md
          echo "- API Tests: ${{ needs.api-tests.result }}" >> test-summary.md
          echo "- E2E Tests: ${{ needs.e2e-tests.result }}" >> test-summary.md
          echo "- Performance Tests: ${{ needs.performance-tests.result }}" >> test-summary.md
          echo "- Security Tests: ${{ needs.security-tests.result }}" >> test-summary.md
          echo "- Accessibility Tests: ${{ needs.accessibility-tests.result }}" >> test-summary.md
          
      - name: "Upload Test Summary"
        uses: actions/upload-artifact@v4
        with:
          name: test-summary-report
          path: test-summary.md
          
      - name: "Notify Test Results"
        run: |
          if [ "${{ needs.unit-tests.result }}" == "success" ] && 
             [ "${{ needs.integration-tests.result }}" == "success" ] && 
             [ "${{ needs.api-tests.result }}" == "success" ] && 
             [ "${{ needs.e2e-tests.result }}" == "success" ]; then
            echo "✅ All critical tests passed!"
          else
            echo "❌ Some tests failed - check individual job results"
            exit 1
          fi
          # Add your notification logic here (Slack, Teams, etc.)